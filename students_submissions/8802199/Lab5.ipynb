{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 5 - Cross-Validation for Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    "\n",
    "1.Utilize the diabetes dataset from lab 4. Perform cross-validation on nine polynomial models, ranging from degree 0 to 8.\n",
    "\n",
    "2.Construct a table summarizing the cross-validation results: Each model should have a separate row in the table. Have the mean and standard deviation of the R-Squared, Mean Absolute Error (MAE) and MAPE metrics for each model.\n",
    "\n",
    "3.Identification of the Best Model: Identify the model that exhibits the highest performance based on the R-Squared, MAE and MAPE metrics. Provide an explanation for choosing this specific model. Run the model on the test set and provide results (R-Squared, MAPE, MAE)\n",
    "    \n",
    "4.Additional analysis and interpretation of the models' performances. Explore further findings beyond the required metrics. The analysis should provide at least one relevant insight about the choice of the best model (for example - an analysis of in which instances does it fail), or further insights comparing the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Degree    R2 Mean  R2 Std Dev    MAE Mean  MAE Std Dev  MAPE Mean   \n",
      "0       0  -0.027907    0.026996   65.924330     5.588439   0.622844  \\\n",
      "1       1   0.470314    0.089697   44.450481     2.993516   0.397483   \n",
      "2       2   0.396881    0.107551   46.496951     3.632944   0.399535   \n",
      "3       3 -12.757003    9.288513  169.420479    49.834302   1.321950   \n",
      "4       4 -58.958412   35.641085  340.133115    65.530133   2.729640   \n",
      "5       5 -48.620679   30.775408  307.366481    55.054135   2.494358   \n",
      "6       6 -48.669635   30.962701  307.211035    54.982721   2.493718   \n",
      "7       7 -48.673806   30.973853  307.208098    54.982389   2.493727   \n",
      "8       8 -48.674386   30.980423  307.201113    54.973845   2.493718   \n",
      "\n",
      "   MAPE Std Dev  \n",
      "0      0.101546  \n",
      "1      0.072758  \n",
      "2      0.065484  \n",
      "3      0.384330  \n",
      "4      0.599754  \n",
      "5      0.524684  \n",
      "6      0.525639  \n",
      "7      0.525721  \n",
      "8      0.525733  \n",
      "Best Model: Degree 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data  # Features/ input data used to predict\n",
    "y = diabetes.target  # Target variable\n",
    "\n",
    "# Prepare cross-validation to split the data into 10 parts for testing and training\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Initialize an empty list to collect results\n",
    "results = []\n",
    "\n",
    "# Loop through polynomial degrees from simplest(0) to complex(8)\n",
    "for degree in range(9):\n",
    "    # Create a pipeline: Polynomial feature transformation followed by linear regression\n",
    "    pipeline = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    \n",
    "    # Initialize empty lists to collect scores for each fold\n",
    "    r2_scores = []\n",
    "    mae_scores = []\n",
    "    mape_scores = []\n",
    "    \n",
    "    # Loop through the cross-validation splits\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Split data into training and testing sets\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Fit the model on the training data\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the testing data\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model using R-squared, MAE, and MAPE\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "        mape_scores.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "    \n",
    "    # Calculate the mean and standard deviation of the evaluation metrics\n",
    "    results.append({\n",
    "        'Degree': degree,\n",
    "        'R2 Mean': np.mean(r2_scores),\n",
    "        'R2 Std Dev': np.std(r2_scores),\n",
    "        'MAE Mean': np.mean(mae_scores),\n",
    "        'MAE Std Dev': np.std(mae_scores),\n",
    "        'MAPE Mean': np.mean(mape_scores),\n",
    "        'MAPE Std Dev': np.std(mape_scores)\n",
    "    })\n",
    "\n",
    "# Convert the results list to a DataFrame for easier viewing and analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# To find the best model, the highest R2 Mean, and the lowest MAE Mean and MAPE Mean are looked at\n",
    "# Example:\n",
    "best_model_idx = results_df['R2 Mean'].idxmax()\n",
    "best_model = results_df.iloc[best_model_idx]\n",
    "print(f'Best Model: Degree {best_model[\"Degree\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Analysis:\n",
    "\n",
    "The performance significantly drops as the degree of the polynomial increases beyond 1. This is evident from the negative R-Squared mean values and increasing MAE and MAPE mean values for higher degree polynomials.\n",
    "\n",
    "From degree 3 onwards, the models perform poorly as indicated by the negative R-Squared values and high error metrics (MAE and MAPE). This suggests that higher-degree polynomial models are overfitting to the training data, capturing noise rather than the underlying trend. Which emphasizes on the fact that it is important to chhose a model with the right amount of complexity. \n",
    "\n",
    "In this case, degree 1 polynomial performs the best.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
