{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 6 - Logistic Regression\n",
    "\n",
    "1. Using SciKit-Learn, train a binary logistic regression model on the Iris dataset. Use all four features and define only 2 labels:        virginica and non-virginica. See the logistic regression notebook presented in class for a demonstration on how to set up these labels.\n",
    "\n",
    "2. Evaluate the model:\n",
    "    i. Failure modes: in which data instances is the model wrong? \n",
    "    ii. Are there any shared properties for these cases?\n",
    "    iii. How is the model doing across a set of evaluation metrics: accuracy and confusion metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "# Separate the feature matrix (X) and target vector (y)\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Convert the multi-class labels to binary labels (1 for Virginica, 0 for others)\n",
    "y_bin = (y == 2).astype(int)\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) sets with a random state for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model object\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "# Train the Logistic Regression model on the training data\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "Confusion Matrix:\n",
      "[[19  0]\n",
      " [ 0 11]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-virginica       1.00      1.00      1.00        19\n",
      "    virginica       1.00      1.00      1.00        11\n",
      "\n",
      "     accuracy                           1.00        30\n",
      "    macro avg       1.00      1.00      1.00        30\n",
      " weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model:\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Identify the indices of misclassified instances\n",
    "misclassified_idx = (y_pred != y_test)\n",
    "X_misclassified = X_test[misclassified_idx]\n",
    "y_misclassified_true = y_test[misclassified_idx]\n",
    "y_misclassified_pred = y_pred[misclassified_idx]\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Other metrics\n",
    "print(classification_report(y_test, y_pred, target_names=[\"non-virginica\", \"virginica\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are no failure modes observed as the model has correctly classified all instances in the testing data.\n",
    "\n",
    " Since there are no incorrect classifications, there are no shared properties to analyze for failure cases.\n",
    "\n",
    "\n",
    " In the above confusion matrices, the values on the diagonal (representing correct classifications) are all non-zero, while the off-diagonal values (representing incorrect classifications) are all zero. This indicates a perfect classification performance by the model.\n",
    " \n",
    "Accuracy is 100%, which is the highest possible value, suggesting an excellent performance by the model.\n",
    "\n",
    "Since the model has achieved perfect classification, all of the metrics(Precision, Recall, f1-score) also yield the highest possible value of 1.00."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classic_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
